\part{Algèbre et théorie des nombres}
\chapter{Anneaux et corps finis}
\section{Anneau des entiers modulo $n$}
\section{Corps finis}
\section{Quelques probl\`emes élémentaires de théorie des nombres}
\subsection{Théorème de Wilson}\footnote{\textbf{Note Historique.} Le théorème de Wilson a été découvert à la fin du dixième siècle par le mathématicien arabe Ibn al-Haytham $(965-1040)$. Le résultat ressurgit, sans démonstration, à la fin du dix-huitième siècle dans les écrits de Edward Waring qui l’attribue en 1770 à son élève John Wilson. L’année suivante, Lagrange en donne deux démonstrations dans son article [LAG]. En fait, Leibniz $(1646-1716)$ connaissait déjà le résultat et sa démonstration mais ne les avait pas publiés (voir [RAS] pour de plus amples considérations historiques).}
\'enoncé du théorème 
\begin{theorem}
 Un entier $p$ strictement plus grand que $1$ est un nombre premier si et seulement s'il divise $(p - 1)! + 1$, c'est-à-dire si et seulement si $(p-1)!+ 1 \equiv 0 (mod p)$
\end{theorem}
\textbf{Indication.}  Quatre démonstrations de ce résultat de Wilson. L'idée directrice des deux premières démonstrations est de remplacer ce calcul de congruence $(\mathbb{Z}/p\mathbb{Z})$ par un calcul dans $\mathbb{F}_{p}$ ce qui va permettre d'utiliser les propriétés d’un corps. L'idée de la troisième démonstration est d’utiliser les théorèmes de Sylow dans le groupe symétrique $\mathbb{\sigma}_{p}$, la quatrième est plutôt combinatoire qui repose sur l'identité algébrique $\Sigma_{i=0}^{n} (-1)^{i} C_n^{p}(x-i)^n = n!$ donnée en théorème l'auteur\footnote{https://arxiv.org/pdf/math/0406086.pdf} ainsi le théorème sera simplement comme
corollaire en remplaçant $n$ par $p-1$
\begin{proof}
A venir!.
\end{proof}
Alain Connes dans son article "Autour du théorème de Wilson"\footnote{Alain Connes, An essay on the Riemann Hypothesis, Open Problems in Mathematics.John Forbes Nash, Jr. Michael Th. Rassias Editors}, donne une approximation du nombre $\pi$ en somme de $sin$
\begin{remark}
Contrairement au petit théorème de Fermat, le théorème de Wilson est une condition nécessaire et suffisante pour tester la primalité. Toutefois, cela conduirait à un test très lent informatiquement, car le calcul de (p-1)! nécessite beaucoup d'opérations.
\end{remark}
\begin{python}
import sympy

def isPrime(n):
 if n == 4: return 
 return bool(math.factorial(n>>1)%n)
\end{python}
\chapter{Polynômes}
 \section{Anneaux et polynômes}
  \subsection{Introduction}
 Nous avons vu au chapitre 2 comment effectuer des calculs sur des expressions formelles, éléments de « l'anneau symbolique ». Dans ce chapitre en va manipuler le module dédié, \textcolor{red}{sympy.polys}, permettant de calculer des algèbres polynomiales sur divers domaines de coefficients implémentant un grand nombre de méthodes  allant d’outils simples comme la division polynomiale à des concepts avancés comprenant les bases de Gröbner et la factorisation multivariée sur des domaines de nombres algébrique:
  \subsection{ Construction d’anneaux de polynômes}
En SymPy, les polynômes, comme beaucoup d’autres objets algébriques, sont en général à coefficients dans un anneau commutatif. C’est le point de vue que nous adoptons, mais la plupart de nos exemples concernent des polynômes sur un corps. Dans tout le chapitre, les lettres A et K désignent respectivement un anneau commutatif et un corps quelconques. La première étape pour mener un calcul dans une structure algébrique est souvent de construire R elle-même. On construit $\mathbb{Q}\left[x\right]$
 \section{Polynômes}
  \subsection{Création et arithmétique de base}
  \subsection{Vue d’ensemble des opérations sur les polynômes}
  \subsection{Changement d’anneau}\footnote{Contrairement à Sage, il peut y être que dans SymPy certain 
  fonctionnalité ne soi pas directement accessible que par passage à la programmation }
Changement d’anneau. La liste exacte des opérations disponibles, leur effet
et leur efficacité dépendent fortement de l’anneau de base. Par exemple, les
polynômes de $ZZ\left['x'\right]$ possèdent une méthode content qui renvoie leur contenu,
c’est-à-dire le pgcd de leurs coefficients ; ceux de $QQ\left['x'\right]$ non, l’opération étant
triviale. La méthode factor existe quant à elle pour tous les polynômes mais
déclenche une exception NotImplementedError pour un polynôme à coefficients
dans SR(le cas de Sage) ou dans $\mathbb{Z}/4\mathbb{Z}$. Par exemple Cette exception signifie que l’opération n’est pas disponible dans Sage pour ce type d’objet bien qu’elle ait un sens mathématiquement.
Il est donc très utile de pouvoir jongler avec les différents anneaux de coefficients
sur lesquels on peut considérer un « même » polynôme. Appliquée à un polynôme
de $A\left['x'\right]$, la méthode change\_ring renvoie son image dans $B\left[x\right]$, quand il y a une
façon naturelle de convertir les coefficients. La conversion est souvent donnée par
un morphisme canonique de A dans B : notamment, change\_ring sert à étendre
l’anneau de base pour disposer de propriétés algébriques supplémentaires. Ici par
exemple, le polynôme p est irréductible sur les entiers, mais se factorise sur R :
 \subsection{Itération}
 \section{Arithmétique euclidienne}
 \subsection{ Divisibilité}
 \subsection{ Idéaux et quotients}
 \subsection{Idéaux}
 \section{ Factorisation et racines}
 \subsection{Factorisation}
 \subsection{ Recherche de racines}
 \subsection{ Résultant}
 \subsection{ Groupe de Galois}
 Par défaut le calcul de groupe de Galois n'est pas disponible dans SymPy, ce qui nous amènes encore
 une fois de programmer en ajoutant des modules, Le groupe de Galois d’un polynôme irréductible $p \in \mathbb{Q}\left[x\right]$ est un objet algébrique qui décrit certaines « symétries » des racines de $p$. Il s’agit d’un objet central de la théorie des équations algébriques. Notamment, l’équation $p\left(x\right) = 0$
est résoluble par radicaux, c’est-à-dire que ses solutions s’expriment à partir des coefficients de $p$ au moyen des quatre opérations et de l'extraction de racine n-ième, si et seulement si le groupe de Galois de $p$ est résoluble.
\section{ Fractions rationnelles}
 \subsection{ Construction et propriétés élémentaires}
 La division de deux polynômes (sur un anneau intègre) produit une fraction rationnelle. Son parent est le corps des fractions de l’anneau de polynômes, qui peut s’obtenir par Frac(R) :
 \section{Séries formelles}
 Une série formelle est une série enGroupes de matrices.tière vue comme une simple suite de coefficients, sans considération de convergence. Plus précisément, si $A$ est un anneau commutatif, on appelle séries formelles (en anglais formal
 power series) d’indéterminée  à coefficients dans  les sommes formelles $\sum_{n=0}^{\infty} a_{n}x^{n}$ où ($a_{n}$) est une suite quelconque d’éléments de $A$. Munies des opérations d’addition et de multiplication naturelles
\[
 \sum_{n=0}^{\infty} a_{n}x^{n} + \sum_{n=0}^{\infty} b_{n}x^{n} = \sum_{n=0}^{\infty} \left(a_{n}+b_{n}\right) x^{n} 
 \],
\[
 \left(\sum_{n=0}^{\infty} a_{n}x^{n}\right) \left(\sum_{n=0}^{\infty} b_{n}x^{n}\right) =  \sum_{n=0}^{\infty} \left( \sum_{n=0}^{\infty} a_{i}b_{j}\right)x^{n}
\], les séries formelles forment un anneau noté $A\left[ \left[ x\right] \right] $.\\

les séries formelles forment un anneau noté Dans un système de calcul formel, ces séries sont utiles pour représenter des fonctions analytiques dont on n'a pas d’écriture exacte. Comme toujours, l’ordinateur fait les calculs, mais c’est à l'utilisateur de leur donner un sens mathématique. À lui par exemple de s’assurer que les séries qu’il manipule sont convergentes. 
 \subsection{Opérations sur les séries tronquées}
 \subsection{Développement de solutions d’équations}
 Face à une équation différentielle dont les solutions exactes sont trop compliquées à calculer ou à exploiter une fois calculées, ou tout simplement qui n’admet pas de solution en forme close, un recours fréquent consiste à chercher des solutions sous forme de séries. On commence habituellement par déterminer les solutions 
de l’équation dans l’espace des séries formelles, et si nécessaire, on conclut ensuite par un argument de convergence que les solutions formelles construites ont un sens analytique. SymPy peut être d’une aide précieuse pour la première étape. Considérons par exemple l’équation différentielle

\begin{example}
\[
 \left(x\right) = \sqrt{1+x^{2}}
\]
\end{example}

%%%%%%%%
\begin{exercise}
Considérons le polynôme $p(x) = a_{0} + a_{1} x + a_{2} x^{2} + a_{3} x^{3}$, où $a_{i} \neq 0$ $\forall i$. Le nombre minimum de multiplications nécessaires pour évaluer $p$ sur une entrée $x$ est:
\end{exercise}
\chapter{Algèbre linéaire}
Ce chapitre traite de l’algèbre linéaire exacte et symbolique, c’est-à-dire sur
des anneaux propres au calcul formel, tels que $Z$, des corps finis, des anneaux de
polynômes. Nous présentons les constructions sur les matrices et leurs espaces ainsi que les
opérations de base, puis les différents calculs possibles sur ces matrices, regroupés en deux thèmes : ceux liés à l’élimination de Gauss et aux transformations par équivalence à gauche, et ceux liés aux valeurs et espaces
propres et aux transformations de similitude.
\section{Constructions et manipulations élémentaires}
\subsection{ Espaces de vecteurs, de matrices}
De la même façon que pour les polynômes, les vecteurs et les matrices sont
manipulés comme des objets algébriques appartenant à un espace. Si les coefficients
appartiennent à un corps $K$, c’est un espace vectoriel sur $K$ ; s’ils appartiennent
à un anneau, c’est un $K-module$ libre.
\textbf{Groupes de matrices.} On poura par ailleur définir des sous-groupes de l'espace total des matrices. Ainsi le constructeur 
\subsection{ Construction des matrices et des vecteurs}
Les matrices et les vecteurs peuvent naturellement être générés comme des éléments d’un espace en fournissant la liste des coefficients en arguments. Pour les matrices, ceux-ci seront lus par ligne :
\subsection{ Manipulations de base et arithmétique sur les matrices}
\textbf{Indices et accès aux coefficients.} L'accès aux coefficients ainsi qu’à des
sous-matrices extraites se fait de façon unifiée par l’opérateur crochet $A$ $\left[i, j\right]$,selon les 
conventions usuelles de Python. Les indices de ligne $i$ et de colonne $j$ peuvent être des entiers (pour 
l’accès à des coefficients) ou des intervalles sous la forme $1:3$ (on rappelle que par convention, en Python 
les indices commencent à $0$, et les intervalles sont toujours inclusifs pour la borne inférieure et exclusifs 
pour la borne supérieure). L’intervalle « : » sans bornes correspond à la totalité des indices possibles dans la 
dimension considérée. La notation $a:b:k$ permet d’accéder aux indices compris entre $a$ et $b-1$ par pas de 
$k$. Enfin, les indices négatifs sont aussi valides, et permettent de parcourir les indices à partir de la
fin. Ainsi $A$ $\left[-2,:\right]$ correspond à l’avant dernière ligne. L'accès à ces sous-matrices
se fait aussi bien en lecture qu’en écriture. On peut par exemple modifier une colonne donnée de la façon 
suivante :
\subsection{ Opérations de base sur les matrices}
Les opérations arithmétiques sur les matrices se font avec les opérateurs usuels +,-,$\ast$,\^. L’inverse 
d’une matrice $A$ peut s’écrire aussi bien $A^-1$ que $~A$. Lorsque $a$ est un scalaire et $A$ une matrice, 
l’opération $a*A$ correspond à la multiplication externe de l’espace de matrices. Pour les autres opérations où 
un scalaire a est fourni en lieu et place d’une matrice (par exemple l’opération a+A), il est considéré comme la 
matrice scalaire correspondante $aI_{n}$ si a $a\neq 0$ et les dimensions le permettent. Le produit élément par 
élément de deux matrices s’effectue avec l’opération elementwise\_product.
\section{ Calculs sur les matrices}
En algèbre linéaire, les matrices peuvent être utilisées pour représenter aussi bien des familles de vecteurs, 
des systèmes d’équations linéaires, des applications linéaires ou des sous-espaces. Ainsi, le calcul d’une 
propriété comme le rang d’une famille, la solution d’un système, les espaces propres d’une application linéaire, 
ou la dimension d’un sous-espace se ramènent à des transformations sur ces matrices révélant cette propriété. 
Ces transformations correspondent à des changements de base, vus au niveau.
\\
Ces transformations correspondent à des changements de base, vus au niveau
matriciel comme des transformations d’équivalence : $B = PAQ^{-1}$ , où $P$ et $Q$ sont
des matrices inversibles. Deux matrices sont dites équivalentes s’il existe une telle

transformation pour passer de l’une à l’autre. On peut ainsi former des classes
d’équivalence pour cette relation, et l’on définit des formes normales, permettant
de caractériser de manière unique chaque classe d’équivalence. Dans ce qui suit,
nous présentons l’essentiel des calculs sur les matrices disponibles avec SymPy, sous
l’angle de deux cas particuliers de ces transformations :

\begin{itemize}
 	 \item Les transformations d’équivalence à gauche, de la forme $B = U A$, qui
révèlent les propriétés caractéristiques pour les familles de vecteurs, telles
que le rang (nombre de vecteurs linéairement indépendants), le déterminant
(volume du parallélépipède décrit par la famille de vecteurs), le profil de rang
(premier sous-ensemble de vecteurs formant une base), . . . L’élimination de
Gauss est l’outil central pour ces transformations, et la forme échelonnée
réduite (forme de Gauss-Jordan dans un corps ou forme de Hermite dans Z)
est la forme normale. En outre, ces transformations servent à la résolution
des systèmes linéaires.
	 \item  Les transformations de similitude, de la forme $B = UAU^{-1}$ , qui révèlent les
propriétés caractéristiques des matrices représentant des endomorphismes,
comme les valeurs propres, les espaces propres, les polynômes minimal et
caractéristique, . . . La forme de Jordan ou la forme de Frobenius, selon les
domaines de calcul, seront les formes normales pour ces transformations.

\end{itemize}




